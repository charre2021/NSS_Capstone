# NSS DS5 Capstone

## Executive Summary
The goal of this project was to web scrape pictures from “[One Tiny Hand](https://onetinyhand.com/)” and build a deep learning model that detects the one tiny hand in each picture. What it turned into was a exploration of image processing and unsupervised and supervised learning techniques.

## Outline
* Part 1: Scrape pictures and save locally. Code located [here](https://github.com/charre2021/NSS_Capstone/blob/main/scrape_pictures.ipynb).
* Part 2: Explore pictures through object-oriented programming in Python, using scikit-image and OpenCV. Code located [here](https://github.com/charre2021/NSS_Capstone/blob/main/explore_pictures.ipynb).
* Part 3: Study and use YOLOv5 and Mask RCNN models to predict the class and bounding boxes for tiny hands and "normal" hands in each image. Code located [here](https://github.com/charre2021/NSS_Capstone/blob/main/YOLOv5.ipynb), [here](https://github.com/charre2021/NSS_Capstone/blob/main/data.yaml) and [here](https://github.com/charre2021/NSS_Capstone/blob/main/create_maskRCNN_model.ipynb).

## Example Findings

* Unsupervised Learning Example 1:

![slic](https://user-images.githubusercontent.com/86251317/173726690-249dada6-1787-4856-ae5c-ea0da0403e56.png)

* Unsupervised Learning Example 2:

![active_contour](https://user-images.githubusercontent.com/86251317/173726712-b648d5d5-4295-46d6-9565-71582e7a90d7.png)

* Additional material in final presentation.

## Final Product

TO BE ADDED.
