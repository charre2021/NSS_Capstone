# NSS DS5 Capstone

## Executive Summary
The goal of this project was to web scrape pictures from “[One Tiny Hand](https://onetinyhand.com/)” and build a deep learning model that detects the one tiny hand in each picture. What it turned into was a exploration of image processing and unsupervised and supervised learning techniques.

## Outline
* Part 1: Scrape pictures and save locally. Code located [here](https://github.com/charre2021/NSS_Capstone/blob/main/scrape_pictures.ipynb).
* Part 2: Explore pictures through object-oriented programming in Python, using scikit-image and OpenCV. Code located [here](https://github.com/charre2021/NSS_Capstone/blob/main/explore_pictures.ipynb).
* Part 3: Study and use YOLOv5 and Mask RCNN models to predict the class and bounding boxes for tiny hands and "normal" hands in each image. Code located [here](https://github.com/charre2021/NSS_Capstone/blob/main/YOLOv5.ipynb), [here](https://github.com/charre2021/NSS_Capstone/blob/main/data.yaml) and [here](https://github.com/charre2021/NSS_Capstone/blob/main/create_maskRCNN_model.ipynb).

## Findings

TO BE ADDED.

## Final Product

TO BE ADDED.
